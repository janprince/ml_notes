{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b42014e-75c5-4455-a862-49ef010262d7",
   "metadata": {},
   "source": [
    "The problem we’re trying to solve here is to classify grayscale images of handwritten\n",
    "digits (28 × 28 pixels) into their 10 categories (0 through 9). \n",
    "\n",
    "We’ll use the MNIST dataset, a classic in the machine learning community, which has been around almost\n",
    "as long as the field itself and has been intensively studied. It’s a set of 60,000 training\n",
    "images, plus 10,000 test images, assembled by the National Institute of Standards and\n",
    "Technology (the NIST in MNIST) in the 1980s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550fdb5-a302-4160-8e05-d9e858e5e449",
   "metadata": {},
   "source": [
    "**NOTE:** In machine learning, a category in a classification problem is called a *class*. Data points are called *samples*. The class associated with a specific sample is called a *label*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e25cf58-ab3a-4ee6-a4e2-88febd517ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e6d1363-69b6-4204-8468-42374b51df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97add13-29f9-439f-b869-e161702fa51c",
   "metadata": {},
   "source": [
    "The **images are encoded as NumPy arrays**, and the **labels are an array of digits, ranging from 0 to 9**. The images and labels have a one-to-one correspondence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b558fc26-1005-4aaa-adf9-8fc0b3675e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape    # a rank-3 tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8f269e-3b69-4465-b913-905b0de7bd75",
   "metadata": {},
   "source": [
    "(60000, 28, 28). So what we have here is a **rank-3 tensor** of 8-bit integers. More precisely, it’s an array of 60,000 matrices of 28 × 28 integers. Each such matrix is a grayscale image, with coefficients between 0 and 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b2c5d6c-70af-430b-9e11-70a8fa6cee09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape    # a vector (rank-1 tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca25fe-0a25-4925-a7c1-a44381065cd3",
   "metadata": {},
   "source": [
    "Let's display the fifth digit in this rank-3 tensor, using the matplotlib library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0705fbcd-2751-468b-af06-1a91ff2d3392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digit = train_images[5]        # a rank-2 tensor (matrix)\n",
    "\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9c5c38c-4831-498a-84eb-02e6281e057d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to confirm the digit lets us print the corresponding label from the train_labels\n",
    "train_labels[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b221753a-4dc1-4234-a3cd-c25a3b34e1ab",
   "metadata": {},
   "source": [
    "### The network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a25a4067-708b-4cb7-9e4d-b78bf21d82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45317156-c56c-4283-8dd8-83f82437aba4",
   "metadata": {},
   "source": [
    "Here, our model consists of a sequence of two Dense layers, which are densely connected (also called fully connected) neural layers. \n",
    "\n",
    "The second (and last) layer is a **10-way softmax classification layer**, which means it will return an array of 10 probability scores\n",
    "(summing to 1). Each score will be the probability that the current digit image belongs to one of our 10 digit classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095bd44-e2b9-4423-8827-1d71dbc571b7",
   "metadata": {},
   "source": [
    "### The compilation step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec71fca0-e83f-46c3-932c-61301e574753",
   "metadata": {},
   "source": [
    "To make the model ready for training, we need to pick three more things as part of the compilation step:\n",
    "\n",
    "1. **An optimizer**—The mechanism through which the model will update itself based on the training data it sees, so as to improve its performance. \n",
    "\n",
    "2. **A loss function**—How the model will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direction.\n",
    "\n",
    "3. **Metrics to monitor during training and testing**—Here, we’ll only care about accuracy (the fraction of the images that were correctly classified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19d676a2-3ae3-456e-a080-a5dc405e2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf8aa5-0633-43c7-93a3-65bd84a1f67c",
   "metadata": {},
   "source": [
    "Before training, we’ll preprocess the data by reshaping it into the shape the model expects and scaling it so that all values are in the [0, 1] interval. Previously, our training images were stored in an array of shape (60000, 28, 28) of type uint8 with values\n",
    "in the [0, 255] interval. We’ll transform it into a float32 array of shape (60000, 28 * 28) with values between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd4eff-536f-4766-ad12-ef24b8a8b8e4",
   "metadata": {},
   "source": [
    "### Preparing the Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80028604-406c-45b3-9393-845e4886fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f32ae-d597-4875-9a3a-9fe67e5da3b8",
   "metadata": {},
   "source": [
    "We’re now ready to train the model, which in Keras is done via a call to the model’s **fit() method** — we fit the model to its training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7838683-b975-4d5f-8ccb-b6bf27926f18",
   "metadata": {},
   "source": [
    "### \"Fitting\" the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5f433eb-9a96-4f52-86e5-72dd0341d553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 8s 14ms/step - loss: 0.2658 - accuracy: 0.9229\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.1083 - accuracy: 0.9682\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0715 - accuracy: 0.9783\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0507 - accuracy: 0.9851\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0381 - accuracy: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x261cf177c70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a29642f-d60b-4176-b3e0-375beb4f5474",
   "metadata": {},
   "source": [
    "Now that we have a trained model, we can use it to predict class probabilities for new digits—images that weren’t part of the training data, like those from the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3fda77-20e1-419a-90dd-3283da57cbc9",
   "metadata": {},
   "source": [
    "### Using the model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fab5c2b-50df-41c8-89f0-a5a5c0172914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 145ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.1534453e-09, 3.7731880e-09, 1.8916296e-06, 5.5976336e-05,\n",
       "       1.6722498e-11, 5.4189247e-08, 1.3283242e-12, 9.9993908e-01,\n",
       "       6.4121110e-08, 2.8672225e-06], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digits = test_images[0: 10]\n",
    "\n",
    "# predict\n",
    "predictions = model.predict(test_digits)\n",
    "\n",
    "predictions[0]       # an array of 10 probability scores for each digit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bcf655-b4e4-47e4-9eb8-2ef7f2920e88",
   "metadata": {},
   "source": [
    "Each number of index i in that array corresponds to the probability that digit image test_digits[0] belongs to class i.\n",
    "\n",
    "This first test digit has the highest probability score (0.99999106, almost 1) at index 7, so according to our model, it must be a 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7108e0fe-0b9c-46f4-8f22-4ef15359583e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83d18413-8701-4775-a659-7d4c8c99e928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999391"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a48435f-14c8-4540-b724-ac40b77870bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can check if the test_labels agree\n",
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e1389-6b65-4ad3-9e05-23e6e348d582",
   "metadata": {},
   "source": [
    "On average, how good is our model at classifying such never-before-seen digits? Let’s check by computing average accuracy over the entire test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d77902-cd32-40b9-9b4d-3ca312d28997",
   "metadata": {},
   "source": [
    "### Evaluating the model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0c9d373-5c83-4fd1-b09b-64624ae09beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0658 - accuracy: 0.9783\n",
      "test_acc: 0.9782999753952026\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accu = model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc: {test_accu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65fca9-08f0-442b-95db-1a5f105b5277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
